{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b90250a",
   "metadata": {},
   "source": [
    "### I worked on mnist dataset (image classification) from scratch, our process contain some stages  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0317428c",
   "metadata": {},
   "source": [
    "### first stage importing important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177bf952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7ee95",
   "metadata": {},
   "source": [
    "### second stage split dataset into \n",
    "1- train data consist of 20000 simple\n",
    "\n",
    "2- test data consist of 1000 simple  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d35b6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc988e300a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train,y_train) , (x_test, y_test) = keras.datasets.mnist.load_data() \n",
    "x_train = x_train[:20000]\n",
    "y_train = y_train[:20000]\n",
    "x_test = x_test[:1000]\n",
    "y_test = y_test[:1000]\n",
    "\n",
    "plt.imshow(x_test[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48d7cb3",
   "metadata": {},
   "source": [
    "### third stage is extracting features from images\n",
    "#### first split each image into small pics \n",
    "i splited each image into -> 16 block each of them represented by -> 7 * 7 pixels                                 \n",
    "I will use center of mass of each block in image that return (x,y) coordinates for each block "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa98be",
   "metadata": {},
   "source": [
    "centroid function calculate and return center of mass of each block \n",
    "\n",
    "input -> small pic \n",
    "output -> (x,y) coordinates of block and if pic is all black return (3.5, 3.5) because pic is 7 * 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8ed64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(grid):\n",
    "    if np.all((grid == 0)):\n",
    "        return (3.5,3.5)\n",
    "    return ndimage.measurements.center_of_mass(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c877633e",
   "metadata": {},
   "source": [
    "4 blocks in width and 4 blocks in hight then we have 16 small pics \n",
    "\n",
    "crop_image function split image into 16 small pics\n",
    "then call centroid function calculate (x,y) coordinates of block\n",
    "then add all centroids into one vector and return it for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25ee1e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crop_feature(test_image, blocks):\n",
    "    rows , cols = int(test_image.shape[0] / blocks), int(test_image.shape[1] / blocks)\n",
    "    vector = list()\n",
    "    k,f = cols,0\n",
    "    for i in range(blocks):\n",
    "        c,z = rows,0\n",
    "        for r in range(blocks):\n",
    "                window = test_image[f:k,z:c]\n",
    "                c += rows\n",
    "                z += rows\n",
    "                x,y = centroid(window)\n",
    "                vector.extend([x,y])\n",
    "        k += cols\n",
    "        f += cols\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300d16c4",
   "metadata": {},
   "source": [
    "### convert x_train and x_test to its new vectors (centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7028769",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = list() \n",
    "x_test1  = list() \n",
    "\n",
    "for i in x_train:\n",
    "    x_train1.append(crop_feature(i,4))\n",
    "\n",
    "for i in x_test:\n",
    "    x_test1.append(crop_feature(i,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1833d528",
   "metadata": {},
   "source": [
    "### implementing KNN from scartch \n",
    "1- calculate euclidean distance between each point from x_test and all point from x_train \n",
    "\n",
    "2- sort distances in ascending order\n",
    "\n",
    "3- return k shortest distances from each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e0e5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def dist(self, point1, point2):\n",
    "        return np.sqrt(np.sum(np.power((point1-point2), 2)))\n",
    "    \n",
    "    \n",
    "    def predict(self, x_train, x_test, y_train, k):\n",
    "        y_train = pd.DataFrame(y_train)\n",
    "        y_pred = list()\n",
    "        \n",
    "        for i in x_test:\n",
    "            dists = list()\n",
    "            for j in x_train:\n",
    "                dis = self.dist(i,j)\n",
    "                dists.append(dis)\n",
    "\n",
    "            \n",
    "            df_dists = pd.DataFrame(data=dists, columns=['dist'], index = y_train[0])\n",
    "            \n",
    "            df_k = df_dists.sort_values(by=['dist'], axis=0)[:k]\n",
    "            df_k = df_k.index\n",
    "            \n",
    "            out = stats.mode(df_k)[0][0]\n",
    "            \n",
    "            y_pred.append(out)\n",
    "            \n",
    "        return y_pred\n",
    "    \n",
    "    def accuracy(self, y_pred, y_test):\n",
    "        con = 0\n",
    "        for i,j in zip(y_pred, y_test):\n",
    "            if(i == j):\n",
    "               con += 1 \n",
    "        return (con / len(y_pred)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a763be5f",
   "metadata": {},
   "source": [
    "### test accuracy with different values of k \n",
    "##### the best accuracy when we make k by 5 \n",
    "##### the lowest by k = 7 because when k increase then normal, voting be harder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f521cff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNN()\n",
    "\n",
    "y_pred = model.predict(x_train1, x_test1, y_train, 1)\n",
    "\n",
    "model.accuracy(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c24db18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_train1, x_test1, y_train, 3)\n",
    "\n",
    "model.accuracy(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c69bb4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_train1, x_test1, y_train, 5)\n",
    "\n",
    "model.accuracy(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f82835df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_train1, x_test1, y_train, 13)\n",
    "\n",
    "model.accuracy(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
